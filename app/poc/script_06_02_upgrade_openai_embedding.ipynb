{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c80e99-4508-4373-b376-8087b548cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==1.93.0 in /home/sparky/.local/lib/python3.10/site-packages (1.93.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (4.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (4.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/sparky/.local/lib/python3.10/site-packages (from openai==1.93.0) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (2.11.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.93.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.93.0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.93.0) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.93.0) (1.0.9)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.93.0) (2025.6.15)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.93.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.93.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.93.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.93.0) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.93.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2449e984-6263-43c1-bbba-81b2c309cb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the specified path\n",
    "load_dotenv(dotenv_path='/home/sparky/.dbt/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9898aee-8a16-46e3-974b-0b3e2dc3b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0b7f9-5f36-4671-8678-7fccb3602dca",
   "metadata": {},
   "source": [
    "## Read Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a69e4a-4397-483d-a455-668b7888e4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>product_name</th><th>sale_price</th><th>ingest_timestamp_utc</th><th>ecommerce_name</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;DermaSense Targeted Dark Spot …</td><td>947.0</td><td>&quot;2025-06-19 3:03:30&quot;</td><td>&quot;ecommerce_01&quot;</td></tr><tr><td>&quot;DermaSense pH Balance Gentle S…</td><td>351.0</td><td>&quot;2025-06-19 3:03:30&quot;</td><td>&quot;ecommerce_02&quot;</td></tr><tr><td>&quot;ActiveVita Youthful Skin Elixi…</td><td>369.0</td><td>&quot;2025-06-19 3:03:30&quot;</td><td>&quot;ecommerce_02&quot;</td></tr><tr><td>&quot;DermaSense pH Balance แชมพูอ่อ…</td><td>351.0</td><td>&quot;2025-06-19 3:03:30&quot;</td><td>&quot;ecommerce_01&quot;</td></tr><tr><td>&quot;DermaSense Luminous Exfoliatin…</td><td>1215.0</td><td>&quot;2025-06-19 3:03:30&quot;</td><td>&quot;ecommerce_01&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────────────────┬────────────┬──────────────────────┬────────────────┐\n",
       "│ product_name                    ┆ sale_price ┆ ingest_timestamp_utc ┆ ecommerce_name │\n",
       "│ ---                             ┆ ---        ┆ ---                  ┆ ---            │\n",
       "│ str                             ┆ f64        ┆ str                  ┆ str            │\n",
       "╞═════════════════════════════════╪════════════╪══════════════════════╪════════════════╡\n",
       "│ DermaSense Targeted Dark Spot … ┆ 947.0      ┆ 2025-06-19 3:03:30   ┆ ecommerce_01   │\n",
       "│ DermaSense pH Balance Gentle S… ┆ 351.0      ┆ 2025-06-19 3:03:30   ┆ ecommerce_02   │\n",
       "│ ActiveVita Youthful Skin Elixi… ┆ 369.0      ┆ 2025-06-19 3:03:30   ┆ ecommerce_02   │\n",
       "│ DermaSense pH Balance แชมพูอ่อ…   ┆ 351.0      ┆ 2025-06-19 3:03:30   ┆ ecommerce_01   │\n",
       "│ DermaSense Luminous Exfoliatin… ┆ 1215.0     ┆ 2025-06-19 3:03:30   ┆ ecommerce_01   │\n",
       "└─────────────────────────────────┴────────────┴──────────────────────┴────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_path = '/opt/spark/work-dir/data/exists_data/raw_embedding_demo.csv'\n",
    "\n",
    "raw_df = pl.read_csv(source=raw_path, has_header=True)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745b2d49-13dc-4d8c-91ba-5b8e542ec18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_01 = raw_df.filter(pl.col(\"ecommerce_name\") == 'ecommerce_01')\n",
    "em_02 = raw_df.filter(pl.col(\"ecommerce_name\") == 'ecommerce_02')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea5e07-2be8-4ba8-a52a-dfc9583b96b1",
   "metadata": {},
   "source": [
    "## Setup & Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09dd1c17-3ef8-4989-a3cc-abd8d89990f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure OPENAI_API_KEY environment variable is set\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266371b4-9aa0-4c28-ae09-b1d91e61cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function: generate text embeddings\n",
    "def generate_embeddings(text):\n",
    "    \"\"\"\n",
    "    Generate embeddings for input text using OpenAI's text-embedding-3-small model.\n",
    "\n",
    "    Args:\n",
    "        text (str or list[str]): The text or list of texts to embed.\n",
    "\n",
    "    Returns:\n",
    "        list or list[list]: A list of embeddings, or a list of lists of embeddings if input was a list.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embeddings = [record.embedding for record in response.data]\n",
    "    return embeddings if isinstance(text, list) else embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91164898-86d5-4810-9bf8-d139ec22f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding cache path\n",
    "embedding_cache_path = \"embeddings_cache.pkl\"\n",
    "\n",
    "# Try to load cached embeddings\n",
    "try:\n",
    "    with open(embedding_cache_path, 'rb') as f:\n",
    "        embedding_cache = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de9a33a-8a0a-4867-ba75-587380816a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function: obtain text embeddings through caching mechanism\n",
    "def embedding_from_string(string: str, embedding_cache=embedding_cache) -> list:\n",
    "    \"\"\"\n",
    "    Get embedding for given text, using cache mechanism to avoid recomputation.\n",
    "\n",
    "    Args:\n",
    "        string (str): The input text to get the embedding for.\n",
    "        embedding_cache (dict): A dictionary used as a cache for embeddings.\n",
    "\n",
    "    Returns:\n",
    "        list: The embedding vector for the input string.\n",
    "    \"\"\"\n",
    "    if string not in embedding_cache.keys():\n",
    "        embedding_cache[string] = generate_embeddings(string)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[string]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10c7e4-7987-4a25-89a6-aa38be2a767b",
   "metadata": {},
   "source": [
    "## Embed base product name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62cafb68-1b8a-49e9-8006-1f3a0cbce81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing base by generating embeddings for all base products...\n"
     ]
    }
   ],
   "source": [
    "# Define a dynamic batch size. You can adjust this value based on API limits and performance.\n",
    "BATCH_SIZE = 60\n",
    "\n",
    "print(\"Preparing base by generating embeddings for all base products...\")\n",
    "# Get all product names from the base dataframe\n",
    "base_names = em_02.select('product_name').to_series().to_list()\n",
    "\n",
    "# 1. Identify which product names are new and need to be embedded.\n",
    "names_to_embed = [name for name in base_names if name not in embedding_cache]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c866cd-c99d-4848-873e-1dfd8eda45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. If there are any new names, process them in manageable batches.\n",
    "if names_to_embed:\n",
    "    total_batches = -(-len(names_to_embed) // BATCH_SIZE)  # Ceiling division to calculate total batches\n",
    "    print(f\"Found {len(names_to_embed)} new products to embed. Processing in {total_batches} batches of up to {BATCH_SIZE} items each...\")\n",
    "    \n",
    "    # Iterate through the new names in chunks of BATCH_SIZE\n",
    "    for i in range(0, len(names_to_embed), BATCH_SIZE):\n",
    "        current_batch_num = (i // BATCH_SIZE) + 1\n",
    "        \n",
    "        # Define the current batch of names\n",
    "        batch_names = names_to_embed[i:i + BATCH_SIZE]\n",
    "        print(f\"  - Processing batch {current_batch_num}/{total_batches} ({len(batch_names)} items)...\")\n",
    "        \n",
    "        # Generate embeddings for the current batch\n",
    "        batch_embeddings = generate_embeddings(batch_names)\n",
    "        \n",
    "        # 3. Update the cache with the newly generated embeddings from this batch\n",
    "        for name, embedding in zip(batch_names, batch_embeddings):\n",
    "            embedding_cache[name] = embedding\n",
    "\n",
    "        # 4. Save the updated cache to disk after each batch. This adds robustness.\n",
    "        #    If the script fails, progress from completed batches is not lost.\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "        print(f\"  - Batch {current_batch_num} processed and cache saved.\")\n",
    "            \n",
    "    print(\"All new embeddings have been generated and cached.\")\n",
    "\n",
    "# 5. Retrieve all embeddings from the cache to ensure the list is complete and in the correct order.\n",
    "base_embeddings = [embedding_cache[name] for name in base_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4258b3b-44fa-44ca-b8e3-136dd777b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>product_name</th><th>embedding</th></tr><tr><td>str</td><td>list[f64]</td></tr></thead><tbody><tr><td>&quot;DermaSense pH Balance Gentle S…</td><td>[0.047305, -0.000145, … -0.017072]</td></tr><tr><td>&quot;ActiveVita Youthful Skin Elixi…</td><td>[0.0062, 0.015389, … -0.002123]</td></tr><tr><td>&quot;DermaSense Acne Control Gel-to…</td><td>[0.005794, 0.001892, … -0.011013]</td></tr><tr><td>&quot;ActiveVita Ocean Omega-3 Salmo…</td><td>[-0.009985, 0.024691, … 0.007499]</td></tr><tr><td>&quot;DermaSense Aqua-Hydrate Soothi…</td><td>[0.054816, 0.011955, … 0.017542]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ product_name                    ┆ embedding                       │\n",
       "│ ---                             ┆ ---                             │\n",
       "│ str                             ┆ list[f64]                       │\n",
       "╞═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ DermaSense pH Balance Gentle S… ┆ [0.047305, -0.000145, … -0.017… │\n",
       "│ ActiveVita Youthful Skin Elixi… ┆ [0.0062, 0.015389, … -0.002123… │\n",
       "│ DermaSense Acne Control Gel-to… ┆ [0.005794, 0.001892, … -0.0110… │\n",
       "│ ActiveVita Ocean Omega-3 Salmo… ┆ [-0.009985, 0.024691, … 0.0074… │\n",
       "│ DermaSense Aqua-Hydrate Soothi… ┆ [0.054816, 0.011955, … 0.01754… │\n",
       "└─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_df = {\n",
    "    'product_name': base_names,\n",
    "    'embedding': base_embeddings\n",
    "}\n",
    "\n",
    "# 2. Now, create the DataFrame from the dictionary\n",
    "product_embeddings_df = pl.DataFrame(data_for_df)\n",
    "product_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e38df-f5fe-45c5-baaf-dfd846caf842",
   "metadata": {},
   "source": [
    "## Find Best Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b94b05b-e185-40e3-b96f-3ca76aa9c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. MODIFIED CORE MATCHING LOGIC ---\n",
    "def find_best_match_in_context(query_name, context_embeddings_np):\n",
    "    \"\"\"\n",
    "    Finds the single most similar product in the context catalog for a given query name.\n",
    "\n",
    "    Args:\n",
    "        query_name (str): The name of the product to query.\n",
    "        context_embeddings_np (numpy.ndarray): NumPy array of embeddings for products in the context.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "               - best_index (int): Index of the single most similar product in the context.\n",
    "               - best_similarity (float): Cosine similarity score for the best match.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query name\n",
    "    query_embedding = embedding_from_string(query_name)\n",
    "\n",
    "    # Calculate cosine similarity between the query embedding and all context embeddings\n",
    "    similarities = np.dot(context_embeddings_np, query_embedding) / \\\n",
    "                   (np.linalg.norm(context_embeddings_np, axis=1) * np.linalg.norm(query_embedding))\n",
    "\n",
    "    # --- CHANGE: Use argmax to find the single best match directly ---\n",
    "    best_index = np.argmax(similarities)\n",
    "    best_similarity = similarities[best_index]\n",
    "\n",
    "    return best_index, best_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5fe5237-af40-44dd-a395-e4fdcc13a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. MODIFIED BATCH API PROCESSING LOGIC ---\n",
    "def prepare_batch_verification_file(product_chunk, context_df, context_embeddings_np, batch_file_path):\n",
    "    \"\"\"\n",
    "    Prepares a JSONL file for the OpenAI Batch API with one-to-one verification requests.\n",
    "    This version instructs the LLM to verify a single candidate and return a simple JSON object.\n",
    "    \"\"\"\n",
    "    custom_id_to_product_map = {}\n",
    "    with open(batch_file_path, 'w') as f:\n",
    "        for i, row in enumerate(product_chunk):\n",
    "            query_product_name = row.get('product_name')\n",
    "            if not query_product_name:\n",
    "                continue\n",
    "\n",
    "            # --- CHANGE: Find only the single best candidate match ---\n",
    "            match_index, _ = find_best_match_in_context(query_product_name, context_embeddings_np)\n",
    "            matched_product_name = context_df.row(match_index, named=True)['product_name']\n",
    "\n",
    "            custom_id = f\"request_{os.path.basename(batch_file_path)}_{i}\"\n",
    "            custom_id_to_product_map[custom_id] = {\n",
    "                'original_row': row,\n",
    "                'candidate_match': matched_product_name,\n",
    "                'match_index': match_index\n",
    "            }\n",
    "\n",
    "            # --- CHANGE: Updated prompt for direct one-to-one comparison ---\n",
    "            prompt = f\"\"\"You are a precise product matching assistant. Your task is to determine if the 'Base Product' and the 'Candidate Product' are the same item.\n",
    "\n",
    "Respond in a valid JSON format with a single key:\n",
    "1. \"match_found\": a boolean (true or false).\n",
    "\n",
    "Base Product:\n",
    "'{query_product_name}'\n",
    "\n",
    "Candidate Product:\n",
    "'{matched_product_name}'\n",
    "\"\"\"\n",
    "\n",
    "            # Create the JSON object for the batch file\n",
    "            json_request = {\n",
    "                \"custom_id\": custom_id,\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in JSON format.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    \"max_tokens\": 50,  # Reduced token need for simpler JSON\n",
    "                    \"temperature\": 0.0,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(json_request) + '\\n')\n",
    "            \n",
    "    return custom_id_to_product_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e626db3d-64aa-4217-9934-c8f65af2291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_job_and_get_results(batch_file_path):\n",
    "    \"\"\"Uploads a file, runs a batch job, waits for completion, and returns results.\"\"\"\n",
    "    if not os.path.exists(batch_file_path) or os.path.getsize(batch_file_path) == 0:\n",
    "        print(\"Batch file is empty or does not exist. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # 1. Upload the file\n",
    "    print(f\"Uploading batch file: {batch_file_path}\")\n",
    "    batch_input_file = client.files.create(file=open(batch_file_path, \"rb\"), purpose=\"batch\")\n",
    "    \n",
    "    # 2. Create the batch job\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_input_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "    print(f\"Batch job created: {batch_job.id}. Waiting for completion...\")\n",
    "\n",
    "    # 3. Poll for completion\n",
    "    while batch_job.status not in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "        time.sleep(30)\n",
    "        batch_job = client.batches.retrieve(batch_job.id)\n",
    "        print(f\"  - Job status: {batch_job.status}\")\n",
    "\n",
    "    if batch_job.status != \"completed\":\n",
    "        print(f\"Batch job did not complete successfully. Status: {batch_job.status}\")\n",
    "        return None\n",
    "\n",
    "    # 4. Retrieve and return results\n",
    "    output_file_id = batch_job.output_file_id\n",
    "    result_content = client.files.content(output_file_id).read()\n",
    "    \n",
    "    results = [json.loads(line) for line in result_content.decode('utf-8').strip().split('\\n')]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48af615d-64cb-436a-84c0-9b5e83a67efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. MODIFIED MAIN PROCESSING SCRIPT ---\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 100 # Can potentially be larger with a simpler process\n",
    "# --- CHANGE: Reflecting user's variable names for clarity ---\n",
    "# df_query corresponds to the new products to be checked.\n",
    "# df_base corresponds to the existing product catalog (like 'product_embeddings_df').\n",
    "df_query = em_01 \n",
    "df_base = product_embeddings_df # Using the name from the user's second snippet\n",
    "base_embeddings_np = np.array(df_base['embedding'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7ccaa25-5566-49f5-a645-fb6f5118588f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting product matching in sequential batches of 100...\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "query_rows = list(df_query.iter_rows(named=True))\n",
    "\n",
    "print(f\"Starting product matching in sequential batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ccb6bb-8adf-46f4-a381-4ed08727c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "333703b6-f8ca-42cc-8dc8-62f245d0841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Chunk 1 (100 products) ---\n",
      "Uploading batch file: batch_input_chunk_1.jsonl\n",
      "Batch job created: batch_685fafff1a308190901e6c2cec8c9125. Waiting for completion...\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: in_progress\n",
      "  - Job status: finalizing\n",
      "  - Job status: completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sale_price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 52\u001b[0m\n\u001b[1;32m     45\u001b[0m         match_embedding \u001b[38;5;241m=\u001b[39m base_embeddings_np[top_match_idx]\n\u001b[1;32m     46\u001b[0m         similarity_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(match_embedding, query_embedding) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(match_embedding) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(query_embedding))\n\u001b[1;32m     48\u001b[0m         results_list\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_product_name (from line)\u001b[39m\u001b[38;5;124m'\u001b[39m: query_product_name,\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_product_name (from watson)\u001b[39m\u001b[38;5;124m'\u001b[39m: top_match_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_name\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_from_line\u001b[39m\u001b[38;5;124m'\u001b[39m: query_product_price,\n\u001b[0;32m---> 52\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_from_watson\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtop_match_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msale_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(similarity_score),\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverified_match\u001b[39m\u001b[38;5;124m'\u001b[39m: is_match \u001b[38;5;66;03m# Directly use the boolean from the LLM\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         })\n\u001b[1;32m     57\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(batch_file_path)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- All chunks processed. Final results compiled. ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sale_price'"
     ]
    }
   ],
   "source": [
    "# Process the query dataframe in sequential chunks\n",
    "for i in range(0, len(query_rows), BATCH_SIZE):\n",
    "    product_chunk = query_rows[i:i + BATCH_SIZE]\n",
    "    chunk_num = (i // BATCH_SIZE) + 1\n",
    "    print(f\"\\n--- Processing Chunk {chunk_num} ({len(product_chunk)} products) ---\")\n",
    "    \n",
    "    # 1. Prepare the batch file with the simplified one-to-one logic\n",
    "    batch_file_path = f\"batch_input_chunk_{chunk_num}.jsonl\"\n",
    "    product_map = prepare_batch_verification_file(product_chunk, df_base, base_embeddings_np, batch_file_path)\n",
    "\n",
    "    # 2. Run the batch job\n",
    "    batch_results = run_batch_job_and_get_results(batch_file_path)\n",
    "    \n",
    "    if not batch_results:\n",
    "        print(f\"Skipping result processing for Chunk {chunk_num} due to batch failure or empty input.\")\n",
    "        continue\n",
    "\n",
    "    # 3. Process the results with simplified JSON parsing\n",
    "    for result in batch_results:\n",
    "        custom_id = result['custom_id']\n",
    "        original_data = product_map.get(custom_id)\n",
    "        \n",
    "        if not original_data:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            llm_output_str = result['response']['body']['choices'][0]['message']['content']\n",
    "            llm_response = json.loads(llm_output_str)\n",
    "            is_match = llm_response.get('match_found', False)\n",
    "\n",
    "        except (json.JSONDecodeError, KeyError, IndexError, TypeError) as e:\n",
    "            print(f\"Could not parse response for {custom_id}: {e}. Treating as no match.\")\n",
    "            is_match = False\n",
    "\n",
    "        query_row = original_data['original_row']\n",
    "        query_product_name = query_row['product_name']\n",
    "        query_product_price = query_row['sale_price']\n",
    "        \n",
    "        # Get info for the single candidate match\n",
    "        top_match_idx = original_data['match_index']\n",
    "        top_match_info = df_base.row(top_match_idx, named=True)\n",
    "            \n",
    "        # Recalculate similarity for reporting\n",
    "        query_embedding = embedding_from_string(query_product_name)\n",
    "        match_embedding = base_embeddings_np[top_match_idx]\n",
    "        similarity_score = np.dot(match_embedding, query_embedding) / (np.linalg.norm(match_embedding) * np.linalg.norm(query_embedding))\n",
    "\n",
    "        results_list.append({\n",
    "            'base_product_name (from line)': query_product_name,\n",
    "            'base_product_name (from watson)': top_match_info['product_name'],\n",
    "            'price_from_line': query_product_price,\n",
    "            'price_from_watson': top_match_info['sale_price'],\n",
    "            'similarity': float(similarity_score),\n",
    "            'verified_match': is_match # Directly use the boolean from the LLM\n",
    "        })\n",
    "\n",
    "    os.remove(batch_file_path)\n",
    "\n",
    "print(\"\\n--- All chunks processed. Final results compiled. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2e965-70d2-49ea-9dd0-54aaf3997ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FINAL STEP: CONVERT RESULTS TO DATAFRAME AND SAVE TO CSV ---\n",
    "if results_list:\n",
    "    print(\"Converting results to a Polars DataFrame...\")\n",
    "    results_df = pl.DataFrame(results_list)\n",
    "\n",
    "    output_filename = \"product_matching_results_simplified.csv\"\n",
    "    try:\n",
    "        results_df.write_csv(output_filename)\n",
    "        print(f\"Successfully saved {len(results_df)} results to '{output_filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results to CSV: {e}\")\n",
    "else:\n",
    "    print(\"No results were generated to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
